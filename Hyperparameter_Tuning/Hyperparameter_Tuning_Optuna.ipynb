{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df563819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna is an automatic hyperparameter optimization (HPO) framework\n",
    "# By default optuna use TPE (Tree-structured Parzen Estimator) algorithm\n",
    "# TPE is a Bayesian optimization method.\n",
    "\n",
    "# How TPE Works:\n",
    "    # It runs some initial random trials.\n",
    "    # It separates results into: Good trials, Bad trials\n",
    "    # It builds probability models:\n",
    "    # l(x) → distribution of good parameters\n",
    "    # g(x) → distribution of bad parameters\n",
    "    # It intelligently selects next hyperparameters\n",
    "    # It remembers previous trials\n",
    "\n",
    "# Choose parameters more likely to be good and less likely to be bad.\n",
    "# Choose parameters more likely to be good and less likely to be bad.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89c155b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Key Term:\n",
    "\n",
    "# 1. Study: A-Z propcess of finding best combination of Hyperparameter to maximize accuracy by using Optuna.\n",
    "    # A study in Optuna is an optimization session that encompasses multiple trails. \n",
    "    # It's essentially a collection of trails aimed at optimizing the objective function\n",
    "    # You can think of a study as the overall experiment or search process.\n",
    "    \n",
    "\n",
    "# 2. Trail: A trail is a single iteration of the optimization process where a specific set of hyperparameters is evaluated.\n",
    "    # Each trails runs the objective function once with a distict set of hyperparametrs.\n",
    "    # One single run \n",
    "    # Example: One trail could involve training a model with a learning rate of 0.01 and a max depth of 5 \n",
    "\n",
    "# 3. Trail Parameter: These are the specific hyperparameter values chosen during a trail.\n",
    "    # Each trail will have a unique a combination of hyperparameter that are evaluated to see how they impact the objective function.\n",
    "    # One trail the learning rate might be 0.001, while the batch size is 32 and \n",
    "    # in another trail the learning rate could be 0.01 and a batch size of 64\n",
    "\n",
    "# 4. Objective Function: It is a function to be optimized (maximized, minimized) during the hyperparameter search.\n",
    "    # It takes hyperparametr as input and returns as a value (accuracy, loss and metric)\n",
    "    # Findout the hidden relationship between hyperparameter(max_depth, n_estimator) and rturn values (accuracy, loss function)\n",
    "    # Example: In a classification task, the objective function could be the cross entropy loss, which optuna seeks to minimize\n",
    "\n",
    "# 5. Sampler; A sampler is the algorithm that suggest which hyperparameters should be evaluated next. \n",
    "    # Opyuna uses the TPE by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48d7c8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with Code\n",
    "\n",
    "# # Import necessary libraries\n",
    "import optuna\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a2e0e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Pima Indian Diabetes dataset from sklearn\n",
    "# Note: Scikit-learn's built-in 'load_diabetes' is a regression dataset.\n",
    "# We will load the actual diabetes dataset from an external source\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Pima Indian Diabetes dataset (from UCI repository)\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI',\n",
    "           'DiabetesPedigreeFunction', 'Age', 'Outcome']\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(url, names=columns)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "275500a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregnancies                 0\n",
      "Glucose                     0\n",
      "BloodPressure               0\n",
      "SkinThickness               0\n",
      "Insulin                     0\n",
      "BMI                         0\n",
      "DiabetesPedigreeFunction    0\n",
      "Age                         0\n",
      "Outcome                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Replace zero values with NaN in columns where zero is not a valid value\n",
    "cols_with_missing_vals = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
    "df[cols_with_missing_vals] = df[cols_with_missing_vals].replace(0, np.nan)\n",
    "\n",
    "# Impute the missing values with the mean of the respective column\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "# Check if there are any remaining missing values\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31ffcb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (537, 8)\n",
      "Test set shape: (231, 8)\n"
     ]
    }
   ],
   "source": [
    "# Extract input features (X) and target (y)\n",
    "X = df.drop('Outcome', axis=1)\n",
    "y = df['Outcome']\n",
    "\n",
    "# Split data into training and test sets (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Optional: Scale the data for better model performance\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Check the shape of the data\n",
    "print(f'Training set shape: {X_train.shape}')\n",
    "print(f'Test set shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a8f273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function\n",
    "def Objective(trial):\n",
    "    # Suggest values for the hyperparameters\n",
    "    n_estimator=trial.suggest_int('n_estimators', 50,200)\n",
    "    max_depth=trial.suggest_int('max_depth', 3,20)\n",
    "\n",
    "    #  Create the RandomForestClassifier with suggested hyperparameters\n",
    "    model=RandomForestClassifier(\n",
    "        n_estimators=n_estimator,\n",
    "        max_depth=max_depth,\n",
    "        random_state=42\n",
    "    )\n",
    "    # Perform 3-fold cross-validation and calculate accuracy \n",
    "    score=cross_val_score(\n",
    "        model, X_train, y_train, \n",
    "        cv=3,\n",
    "        scoring='accuracy'\n",
    "    ).mean()\n",
    "\n",
    "    # Return the accuracy score for Optuna to maximize\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a79310",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-17 21:26:19,436]\u001b[0m A new study created in memory with name: no-name-4e9351a4-8f5a-4b96-83ed-e0a9a4fe9887\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:20,315]\u001b[0m Trial 0 finished with value: 0.7709497206703911 and parameters: {'n_estimators': 165, 'max_depth': 14}. Best is trial 0 with value: 0.7709497206703911.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:20,714]\u001b[0m Trial 1 finished with value: 0.7672253258845437 and parameters: {'n_estimators': 80, 'max_depth': 14}. Best is trial 0 with value: 0.7709497206703911.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:21,017]\u001b[0m Trial 2 finished with value: 0.7616387337057727 and parameters: {'n_estimators': 60, 'max_depth': 10}. Best is trial 0 with value: 0.7709497206703911.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:21,413]\u001b[0m Trial 3 finished with value: 0.7635009310986964 and parameters: {'n_estimators': 81, 'max_depth': 9}. Best is trial 0 with value: 0.7709497206703911.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:22,144]\u001b[0m Trial 4 finished with value: 0.7672253258845437 and parameters: {'n_estimators': 140, 'max_depth': 12}. Best is trial 0 with value: 0.7709497206703911.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:23,011]\u001b[0m Trial 5 finished with value: 0.7672253258845437 and parameters: {'n_estimators': 195, 'max_depth': 5}. Best is trial 0 with value: 0.7709497206703911.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:23,363]\u001b[0m Trial 6 finished with value: 0.7709497206703911 and parameters: {'n_estimators': 66, 'max_depth': 18}. Best is trial 0 with value: 0.7709497206703911.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:24,205]\u001b[0m Trial 7 finished with value: 0.7709497206703911 and parameters: {'n_estimators': 178, 'max_depth': 20}. Best is trial 0 with value: 0.7709497206703911.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:24,639]\u001b[0m Trial 8 finished with value: 0.7635009310986964 and parameters: {'n_estimators': 96, 'max_depth': 4}. Best is trial 0 with value: 0.7709497206703911.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:25,342]\u001b[0m Trial 9 finished with value: 0.7690875232774674 and parameters: {'n_estimators': 145, 'max_depth': 18}. Best is trial 0 with value: 0.7709497206703911.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:26,153]\u001b[0m Trial 10 finished with value: 0.7672253258845437 and parameters: {'n_estimators': 160, 'max_depth': 15}. Best is trial 0 with value: 0.7709497206703911.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:26,661]\u001b[0m Trial 11 finished with value: 0.7690875232774674 and parameters: {'n_estimators': 102, 'max_depth': 16}. Best is trial 0 with value: 0.7709497206703911.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:27,233]\u001b[0m Trial 12 finished with value: 0.7821229050279329 and parameters: {'n_estimators': 119, 'max_depth': 20}. Best is trial 12 with value: 0.7821229050279329.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:27,847]\u001b[0m Trial 13 finished with value: 0.7765363128491621 and parameters: {'n_estimators': 118, 'max_depth': 20}. Best is trial 12 with value: 0.7821229050279329.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:28,420]\u001b[0m Trial 14 finished with value: 0.7746741154562384 and parameters: {'n_estimators': 112, 'max_depth': 20}. Best is trial 12 with value: 0.7821229050279329.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:29,064]\u001b[0m Trial 15 finished with value: 0.7783985102420856 and parameters: {'n_estimators': 127, 'max_depth': 18}. Best is trial 12 with value: 0.7821229050279329.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:29,714]\u001b[0m Trial 16 finished with value: 0.7728119180633147 and parameters: {'n_estimators': 136, 'max_depth': 17}. Best is trial 12 with value: 0.7821229050279329.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:30,266]\u001b[0m Trial 17 finished with value: 0.7746741154562384 and parameters: {'n_estimators': 117, 'max_depth': 12}. Best is trial 12 with value: 0.7821229050279329.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:30,896]\u001b[0m Trial 18 finished with value: 0.7672253258845437 and parameters: {'n_estimators': 134, 'max_depth': 6}. Best is trial 12 with value: 0.7821229050279329.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:31,637]\u001b[0m Trial 19 finished with value: 0.7746741154562384 and parameters: {'n_estimators': 153, 'max_depth': 18}. Best is trial 12 with value: 0.7821229050279329.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:32,104]\u001b[0m Trial 20 finished with value: 0.7635009310986964 and parameters: {'n_estimators': 96, 'max_depth': 8}. Best is trial 12 with value: 0.7821229050279329.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:33,015]\u001b[0m Trial 21 finished with value: 0.7821229050279329 and parameters: {'n_estimators': 119, 'max_depth': 20}. Best is trial 12 with value: 0.7821229050279329.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:34,238]\u001b[0m Trial 22 finished with value: 0.7765363128491619 and parameters: {'n_estimators': 124, 'max_depth': 19}. Best is trial 12 with value: 0.7821229050279329.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:34,744]\u001b[0m Trial 23 finished with value: 0.7746741154562384 and parameters: {'n_estimators': 106, 'max_depth': 17}. Best is trial 12 with value: 0.7821229050279329.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:35,505]\u001b[0m Trial 24 finished with value: 0.7765363128491621 and parameters: {'n_estimators': 128, 'max_depth': 20}. Best is trial 12 with value: 0.7821229050279329.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:35,910]\u001b[0m Trial 25 finished with value: 0.7616387337057727 and parameters: {'n_estimators': 83, 'max_depth': 16}. Best is trial 12 with value: 0.7821229050279329.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:36,524]\u001b[0m Trial 26 finished with value: 0.7765363128491619 and parameters: {'n_estimators': 126, 'max_depth': 19}. Best is trial 12 with value: 0.7821229050279329.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:37,266]\u001b[0m Trial 27 finished with value: 0.7616387337057727 and parameters: {'n_estimators': 149, 'max_depth': 14}. Best is trial 12 with value: 0.7821229050279329.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:37,716]\u001b[0m Trial 28 finished with value: 0.7653631284916201 and parameters: {'n_estimators': 90, 'max_depth': 16}. Best is trial 12 with value: 0.7821229050279329.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:38,533]\u001b[0m Trial 29 finished with value: 0.7728119180633147 and parameters: {'n_estimators': 166, 'max_depth': 14}. Best is trial 12 with value: 0.7821229050279329.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:39,053]\u001b[0m Trial 30 finished with value: 0.7690875232774674 and parameters: {'n_estimators': 108, 'max_depth': 19}. Best is trial 12 with value: 0.7821229050279329.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:39,630]\u001b[0m Trial 31 finished with value: 0.7746741154562384 and parameters: {'n_estimators': 120, 'max_depth': 20}. Best is trial 12 with value: 0.7821229050279329.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:40,276]\u001b[0m Trial 32 finished with value: 0.7746741154562384 and parameters: {'n_estimators': 132, 'max_depth': 18}. Best is trial 12 with value: 0.7821229050279329.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:40,817]\u001b[0m Trial 33 finished with value: 0.7783985102420856 and parameters: {'n_estimators': 113, 'max_depth': 19}. Best is trial 12 with value: 0.7821229050279329.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:41,367]\u001b[0m Trial 34 finished with value: 0.7783985102420856 and parameters: {'n_estimators': 113, 'max_depth': 17}. Best is trial 12 with value: 0.7821229050279329.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:42,045]\u001b[0m Trial 35 finished with value: 0.7690875232774674 and parameters: {'n_estimators': 142, 'max_depth': 19}. Best is trial 12 with value: 0.7821229050279329.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:42,541]\u001b[0m Trial 36 finished with value: 0.7709497206703911 and parameters: {'n_estimators': 102, 'max_depth': 13}. Best is trial 12 with value: 0.7821229050279329.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:42,892]\u001b[0m Trial 37 finished with value: 0.7560521415270017 and parameters: {'n_estimators': 72, 'max_depth': 10}. Best is trial 12 with value: 0.7821229050279329.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:43,159]\u001b[0m Trial 38 finished with value: 0.7653631284916201 and parameters: {'n_estimators': 51, 'max_depth': 15}. Best is trial 12 with value: 0.7821229050279329.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:43,599]\u001b[0m Trial 39 finished with value: 0.7765363128491619 and parameters: {'n_estimators': 91, 'max_depth': 18}. Best is trial 12 with value: 0.7821229050279329.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:44,406]\u001b[0m Trial 40 finished with value: 0.7709497206703911 and parameters: {'n_estimators': 169, 'max_depth': 19}. Best is trial 12 with value: 0.7821229050279329.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:44,954]\u001b[0m Trial 41 finished with value: 0.7783985102420856 and parameters: {'n_estimators': 113, 'max_depth': 17}. Best is trial 12 with value: 0.7821229050279329.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:45,555]\u001b[0m Trial 42 finished with value: 0.7783985102420857 and parameters: {'n_estimators': 124, 'max_depth': 17}. Best is trial 12 with value: 0.7821229050279329.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:46,156]\u001b[0m Trial 43 finished with value: 0.7802607076350093 and parameters: {'n_estimators': 125, 'max_depth': 20}. Best is trial 12 with value: 0.7821229050279329.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:46,829]\u001b[0m Trial 44 finished with value: 0.7690875232774674 and parameters: {'n_estimators': 138, 'max_depth': 20}. Best is trial 12 with value: 0.7821229050279329.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:47,461]\u001b[0m Trial 45 finished with value: 0.7783985102420856 and parameters: {'n_estimators': 131, 'max_depth': 20}. Best is trial 12 with value: 0.7821229050279329.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:48,055]\u001b[0m Trial 46 finished with value: 0.7783985102420857 and parameters: {'n_estimators': 122, 'max_depth': 15}. Best is trial 12 with value: 0.7821229050279329.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:48,809]\u001b[0m Trial 47 finished with value: 0.7690875232774674 and parameters: {'n_estimators': 155, 'max_depth': 15}. Best is trial 12 with value: 0.7821229050279329.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:49,401]\u001b[0m Trial 48 finished with value: 0.7765363128491621 and parameters: {'n_estimators': 122, 'max_depth': 16}. Best is trial 12 with value: 0.7821229050279329.\u001b[0m\n",
      "\u001b[32m[I 2026-02-17 21:26:50,081]\u001b[0m Trial 49 finished with value: 0.7709497206703911 and parameters: {'n_estimators': 144, 'max_depth': 13}. Best is trial 12 with value: 0.7821229050279329.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Create a study object and optimize the objective function\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    sampler=optuna.samplers.TPESampler() # Also can use RandomSampler(), GridSampler(search_space)\n",
    "    )  # We aim to maximize accuracy \n",
    "\n",
    "# Run 50 trials to find the best hyperparameters\n",
    "study.optimize(Objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61c8e7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial accuracy: 0.7821229050279329\n",
      "Best hyperparameters: {'n_estimators': 119, 'max_depth': 20}\n"
     ]
    }
   ],
   "source": [
    "# Print the best result\n",
    "print(f'Best trial accuracy: {study.best_trial.value}')\n",
    "print(f'Best hyperparameters: {study.best_trial.params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73e3e22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy with best hyperparameters: 0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Train a RandomForestClassifier using the best hyperparameters from Optuna\n",
    "best_model = RandomForestClassifier(**study.best_trial.params, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy on the test set\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the test accuracy\n",
    "print(f'Test Accuracy with best hyperparameters: {test_accuracy:.2f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
