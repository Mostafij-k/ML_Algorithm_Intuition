{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df563819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna is an automatic hyperparameter optimization (HPO) framework\n",
    "# By default optuna use TPE (Tree-structured Parzen Estimator) algorithm\n",
    "# TPE is a Bayesian optimization method.\n",
    "\n",
    "# How TPE Works:\n",
    "    # It runs some initial random trials.\n",
    "    # It separates results into: Good trials, Bad trials\n",
    "    # It builds probability models:\n",
    "    # l(x) → distribution of good parameters\n",
    "    # g(x) → distribution of bad parameters\n",
    "    # It intelligently selects next hyperparameters\n",
    "    # It remembers previous trials\n",
    "\n",
    "# Choose parameters more likely to be good and less likely to be bad.\n",
    "# Choose parameters more likely to be good and less likely to be bad.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89c155b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Key Term:\n",
    "\n",
    "# 1. Study: A-Z propcess of finding best combination of Hyperparameter to maximize accuracy by using Optuna.\n",
    "    # A study in Optuna is an optimization session that encompasses multiple trails. \n",
    "    # It's essentially a collection of trails aimed at optimizing the objective function\n",
    "    # You can think of a study as the overall experiment or search process.\n",
    "    \n",
    "\n",
    "# 2. Trail: A trail is a single iteration of the optimization process where a specific set of hyperparameters is evaluated.\n",
    "    # Each trails runs the objective function once with a distict set of hyperparametrs.\n",
    "    # One single run \n",
    "    # Example: One trail could involve training a model with a learning rate of 0.01 and a max depth of 5 \n",
    "\n",
    "# 3. Trail Parameter: These are the specific hyperparameter values chosen during a trail.\n",
    "    # Each trail will have a unique a combination of hyperparameter that are evaluated to see how they impact the objective function.\n",
    "    # One trail the learning rate might be 0.001, while the batch size is 32 and \n",
    "    # in another trail the learning rate could be 0.01 and a batch size of 64\n",
    "\n",
    "# 4. Objective Function: It is a function to be optimized (maximized, minimized) during the hyperparameter search.\n",
    "    # It takes hyperparametr as input and returns as a value (accuracy, loss and metric)\n",
    "    # Findout the hidden relationship between hyperparameter(max_depth, n_estimator) and rturn values (accuracy, loss function)\n",
    "    # Example: In a classification task, the objective function could be the cross entropy loss, which optuna seeks to minimize\n",
    "\n",
    "# 5. Sampler; A sampler is the algorithm that suggest which hyperparameters should be evaluated next. \n",
    "    # Opyuna uses the TPE by default."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
